{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Basics\n",
    "\n",
    "A prompt is a piece of text that conveys to a LLM what the user wants. What the user wants can be many things like:\n",
    "\n",
    "- Asking a question\n",
    "- Giving an instruction\n",
    "- Etc...\n",
    "\n",
    "The key components of a prompt are:\n",
    "1. Instruction: where you describe what you want\n",
    "2. Context: additional information to help with performance\n",
    "3. Input data: data the model has not seem to illustrate what you need\n",
    "4. Output indicator: How you prime the model to output what you want, for example asking the model [\"Let's think step by step\" and the end of a prompt can boost reasoning performance](https://arxiv.org/pdf/2201.11903.pdf). You can also write \"Output:\" to prime the model to just write the output and nothing else.\n",
    "\n",
    "[Prompts can also be seen as a form of programming that can customize the outputs and interactions with an LLM.](https://ar5iv.labs.arxiv.org/html/2302.11382#:~:text=prompts%20are%20also%20a%20form%20of%20programming%20that%20can%20customize%20the%20outputs%20and%20interactions%20with%20an%20llm.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Extract the links from this text:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "In the evolving field of artificial intelligence, recent studies have highlighted the profound impact of large language models (LLMs) on natural language processing capabilities. Smith et al. (2023) in their groundbreaking research, presented in the Journal of AI Research, discussed how the integration of LLMs has revolutionized machine translation, making it significantly more accurate and context-aware (https://www.journalofairesearch.org/integration-of-llms). This leap in technology underscores the need for continuous innovation and ethical considerations in AI development. Additionally, the work by Davis and O'Neil (2024) sheds light on the ethical implications of LLMs in content generation, revealing potential biases that could perpetuate misinformation if not addressed properly (https://www.ethicsinaijournal.org/llm-content-generation-implications).\n",
       "\n",
       "Conversely, initiatives to make LLMs more transparent and accountable have been gaining traction. The OpenAI team's recent publication (2025) in the AI Transparency Review highlights the successful implementation of new algorithms that enhance the interpretability of LLM decisions, thereby making them more reliable and trustworthy (https://www.aitransparencyreview.org/enhancing-llm-interpretability). According to Anderson and Yamamoto (2025), these advancements not only contribute to the reliability of AI systems but also foster a deeper understanding among users, facilitating a more informed and responsible use of AI technologies (https://www.aiuserinsights.org/understanding-ai-decisions). This body of work underscores the dynamic nature of AI research and the collaborative effort required to harness the full potential of LLMs while mitigating associated risks.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = \"\"\"\n",
    "In the evolving field of artificial intelligence, recent studies have highlighted the profound impact of large language models (LLMs) on natural language processing capabilities. Smith et al. (2023) in their groundbreaking research, presented in the Journal of AI Research, discussed how the integration of LLMs has revolutionized machine translation, making it significantly more accurate and context-aware (https://www.journalofairesearch.org/integration-of-llms). This leap in technology underscores the need for continuous innovation and ethical considerations in AI development. Additionally, the work by Davis and O'Neil (2024) sheds light on the ethical implications of LLMs in content generation, revealing potential biases that could perpetuate misinformation if not addressed properly (https://www.ethicsinaijournal.org/llm-content-generation-implications).\n",
    "\n",
    "Conversely, initiatives to make LLMs more transparent and accountable have been gaining traction. The OpenAI team's recent publication (2025) in the AI Transparency Review highlights the successful implementation of new algorithms that enhance the interpretability of LLM decisions, thereby making them more reliable and trustworthy (https://www.aitransparencyreview.org/enhancing-llm-interpretability). According to Anderson and Yamamoto (2025), these advancements not only contribute to the reliability of AI systems but also foster a deeper understanding among users, facilitating a more informed and responsible use of AI technologies (https://www.aiuserinsights.org/understanding-ai-decisions). This body of work underscores the dynamic nature of AI research and the collaborative effort required to harness the full potential of LLMs while mitigating associated risks.\n",
    "\"\"\"\n",
    "\n",
    "Markdown(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def get_response(prompt_question):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful research and programming assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the links extracted from the text:\n",
       "\n",
       "1. https://www.journalofairesearch.org/integration-of-llms\n",
       "2. https://www.ethicsinaijournal.org/llm-content-generation-implications\n",
       "3. https://www.aitransparencyreview.org/enhancing-llm-interpretability\n",
       "4. https://www.aiuserinsights.org/understanding-ai-decisions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = instruction + input_data\n",
    "\n",
    "output = get_response(prompt)\n",
    "\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Data & Context Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"You are a url extraction engine. You will be fed text and return ONLY a list containing all the urls in the text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a url extraction engine. You will be fed text and return ONLY a list containing all the urls in the text.\n",
       "\n",
       "Extract the links from this text:\n",
       "\n",
       "In the evolving field of artificial intelligence, recent studies have highlighted the profound impact of large language models (LLMs) on natural language processing capabilities. Smith et al. (2023) in their groundbreaking research, presented in the Journal of AI Research, discussed how the integration of LLMs has revolutionized machine translation, making it significantly more accurate and context-aware (https://www.journalofairesearch.org/integration-of-llms). This leap in technology underscores the need for continuous innovation and ethical considerations in AI development. Additionally, the work by Davis and O'Neil (2024) sheds light on the ethical implications of LLMs in content generation, revealing potential biases that could perpetuate misinformation if not addressed properly (https://www.ethicsinaijournal.org/llm-content-generation-implications).\n",
       "\n",
       "Conversely, initiatives to make LLMs more transparent and accountable have been gaining traction. The OpenAI team's recent publication (2025) in the AI Transparency Review highlights the successful implementation of new algorithms that enhance the interpretability of LLM decisions, thereby making them more reliable and trustworthy (https://www.aitransparencyreview.org/enhancing-llm-interpretability). According to Anderson and Yamamoto (2025), these advancements not only contribute to the reliability of AI systems but also foster a deeper understanding among users, facilitating a more informed and responsible use of AI technologies (https://www.aiuserinsights.org/understanding-ai-decisions). This body of work underscores the dynamic nature of AI research and the collaborative effort required to harness the full potential of LLMs while mitigating associated risks.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = context + \"\\n\\n\" + instruction + \"\\n\" + input_data\n",
    "\n",
    "Markdown(prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the list of URLs extracted from the provided text:\n",
       "\n",
       "1. https://www.journalofairesearch.org/integration-of-llms\n",
       "2. https://www.ethicsinaijournal.org/llm-content-generation-implications\n",
       "3. https://www.aitransparencyreview.org/enhancing-llm-interpretability\n",
       "4. https://www.aiuserinsights.org/understanding-ai-decisions\n",
       "\n",
       "Let me know if you need any further assistance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_response(prompt)\n",
    "\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_indicator = \"Output:\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = context + \"\\n\\n\" + instruction + \"\\n\" + input_data + \"\\n\" + output_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a url extraction engine. You will be fed text and return ONLY a list containing all the urls in the text.\n",
       "\n",
       "Extract the links from this text:\n",
       "\n",
       "In the evolving field of artificial intelligence, recent studies have highlighted the profound impact of large language models (LLMs) on natural language processing capabilities. Smith et al. (2023) in their groundbreaking research, presented in the Journal of AI Research, discussed how the integration of LLMs has revolutionized machine translation, making it significantly more accurate and context-aware (https://www.journalofairesearch.org/integration-of-llms). This leap in technology underscores the need for continuous innovation and ethical considerations in AI development. Additionally, the work by Davis and O'Neil (2024) sheds light on the ethical implications of LLMs in content generation, revealing potential biases that could perpetuate misinformation if not addressed properly (https://www.ethicsinaijournal.org/llm-content-generation-implications).\n",
       "\n",
       "Conversely, initiatives to make LLMs more transparent and accountable have been gaining traction. The OpenAI team's recent publication (2025) in the AI Transparency Review highlights the successful implementation of new algorithms that enhance the interpretability of LLM decisions, thereby making them more reliable and trustworthy (https://www.aitransparencyreview.org/enhancing-llm-interpretability). According to Anderson and Yamamoto (2025), these advancements not only contribute to the reliability of AI systems but also foster a deeper understanding among users, facilitating a more informed and responsible use of AI technologies (https://www.aiuserinsights.org/understanding-ai-decisions). This body of work underscores the dynamic nature of AI research and the collaborative effort required to harness the full potential of LLMs while mitigating associated risks.\n",
       "\n",
       "Output:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[\"https://www.journalofairesearch.org/integration-of-llms\", \"https://www.ethicsinaijournal.org/llm-content-generation-implications\", \"https://www.aitransparencyreview.org/enhancing-llm-interpretability\", \"https://www.aiuserinsights.org/understanding-ai-decisions\"]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_response(prompt)\n",
    "\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "outputlist = literal_eval(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.journalofairesearch.org/integration-of-llms',\n",
       " 'https://www.ethicsinaijournal.org/llm-content-generation-implications',\n",
       " 'https://www.aitransparencyreview.org/enhancing-llm-interpretability',\n",
       " 'https://www.aiuserinsights.org/understanding-ai-decisions']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT](https://ar5iv.labs.arxiv.org/html/2302.11382)\n",
    "- [Prompt-Engineering-Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)\n",
    "- [A Survey of Large Language Models](https://arxiv.org/pdf/2303.18223.pdf)\n",
    "- [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/pdf/2107.13586.pdf)\n",
    "- [prompt engineering guide - zero shot prompting example](https://www.promptingguide.ai/techniques/zeroshot)\n",
    "- [Finetuned language models are zero-shot learners](https://arxiv.org/pdf/2109.01652.pdf)\n",
    "- [prompt engineering guide - few shot prompting](https://www.promptingguide.ai/techniques/fewshot)\n",
    "- [prompt engineering guide - chain of thought prompting](https://www.promptingguide.ai/techniques/cot)\n",
    "- [Wei et al. (2022)](https://arxiv.org/abs/2201.11903)\n",
    "- [prompt engineering guide - self-consistency](https://www.promptingguide.ai/techniques/consistency)\n",
    "- [prompt engineering guide - generate knowledge](https://www.promptingguide.ai/techniques/knowledge)\n",
    "- [Liu et al. 2022](https://arxiv.org/pdf/2110.08387.pdf)\n",
    "- [prompt engineering guide - tree of thoughts (ToT)](https://www.promptingguide.ai/techniques/tot)\n",
    "- [Prompt Engineering by Lilian Weng](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)\n",
    "- [Prompt Engineering vs. Blind Prompting](https://mitchellh.com/writing/prompt-engineering-vs-blind-prompting#the-demonstration-set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-prompt-eng",
   "language": "python",
   "name": "oreilly-prompt-eng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

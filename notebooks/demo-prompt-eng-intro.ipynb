{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to set your OpenAI API key in the .env file\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1. Break the problem down into sub-problems\n",
    "2. 1 prompt per sub-problem\n",
    "3. Evaluate performance on each sub-problem\n",
    "4. Compose your successful prompts\n",
    "5. ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task:__\n",
    "\n",
    "__Automatic reference section from a markdown essay.__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking it down\n",
    "\n",
    "1. Identify all the citations with the respective source\n",
    "2. For each citation produce the correct reference bullet point\n",
    "3. Convert to a markdown format with the url hyper link syntax: `[]()`\n",
    "4. Add the reference section at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, why separate the second part and write Python code rather than ask the model? Because since this second part is deterministic, \n",
    "we save in tokens as well as in complexity where the model can focus only on the problem of correctly extracting the citations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example draft essay:\n",
    "\n",
    "```\n",
    "In the evolving field of artificial intelligence, recent studies have highlighted the profound impact of large language models (LLMs) on natural language processing capabilities. Smith et al. (2023) in their groundbreaking research, presented in the Journal of AI Research, discussed how the integration of LLMs has revolutionized machine translation, making it significantly more accurate and context-aware (https://www.journalofairesearch.org/integration-of-llms). This leap in technology underscores the need for continuous innovation and ethical considerations in AI development. Additionally, the work by Davis and O'Neil (2024) sheds light on the ethical implications of LLMs in content generation, revealing potential biases that could perpetuate misinformation if not addressed properly (https://www.ethicsinaijournal.org/llm-content-generation-implications).\n",
    "\n",
    "Conversely, initiatives to make LLMs more transparent and accountable have been gaining traction. The OpenAI team's recent publication (2025) in the AI Transparency Review highlights the successful implementation of new algorithms that enhance the interpretability of LLM decisions, thereby making them more reliable and trustworthy (https://www.aitransparencyreview.org/enhancing-llm-interpretability). According to Anderson and Yamamoto (2025), these advancements not only contribute to the reliability of AI systems but also foster a deeper understanding among users, facilitating a more informed and responsible use of AI technologies (https://www.aiuserinsights.org/understanding-ai-decisions). This body of work underscores the dynamic nature of AI research and the collaborative effort required to harness the full potential of LLMs while mitigating associated risks.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def get_response(prompt_question):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful research and programming assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Extract all the citations in the following draft essay with their respective source:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"\"\"'''\\nIn the evolving field of artificial intelligence, recent studies have highlighted the profound impact of large language models (LLMs) on natural language processing capabilities. Smith et al. (2023) in their groundbreaking research, presented in the Journal of AI Research, discussed how the integration of LLMs has revolutionized machine translation, making it significantly more accurate and context-aware (https://www.journalofairesearch.org/integration-of-llms). This leap in technology underscores the need for continuous innovation and ethical considerations in AI development. Additionally, the work by Davis and O'Neil (2024) sheds light on the ethical implications of LLMs in content generation, revealing potential biases that could perpetuate misinformation if not addressed properly (https://www.ethicsinaijournal.org/llm-content-generation-implications).\n",
    "\n",
    "Conversely, initiatives to make LLMs more transparent and accountable have been gaining traction. The OpenAI team's recent publication (2025) in the AI Transparency Review highlights the successful implementation of new algorithms that enhance the interpretability of LLM decisions, thereby making them more reliable and trustworthy (https://www.aitransparencyreview.org/enhancing-llm-interpretability). According to Anderson and Yamamoto (2025), these advancements not only contribute to the reliability of AI systems but also foster a deeper understanding among users, facilitating a more informed and responsible use of AI technologies (https://www.aiuserinsights.org/understanding-ai-decisions). This body of work underscores the dynamic nature of AI research and the collaborative effort required to harness the full potential of LLMs while mitigating associated risks. '''\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\"\n",
    "output_indicator = \"Your output should be just bullet points containing all the citations and their sources. Output: \\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\n",
       "\n",
       "Extract all the citations in the following draft essay with their respective source and output a bullet list with all the citations and their sources.\n",
       "\n",
       "'''\n",
       "In the evolving field of artificial intelligence, recent studies have highlighted the profound impact of large language models (LLMs) on natural language processing capabilities. Smith et al. (2023) in their groundbreaking research, presented in the Journal of AI Research, discussed how the integration of LLMs has revolutionized machine translation, making it significantly more accurate and context-aware (https://www.journalofairesearch.org/integration-of-llms). This leap in technology underscores the need for continuous innovation and ethical considerations in AI development. Additionally, the work by Davis and O'Neil (2024) sheds light on the ethical implications of LLMs in content generation, revealing potential biases that could perpetuate misinformation if not addressed properly (https://www.ethicsinaijournal.org/llm-content-generation-implications).\n",
       "\n",
       "Conversely, initiatives to make LLMs more transparent and accountable have been gaining traction. The OpenAI team's recent publication (2025) in the AI Transparency Review highlights the successful implementation of new algorithms that enhance the interpretability of LLM decisions, thereby making them more reliable and trustworthy (https://www.aitransparencyreview.org/enhancing-llm-interpretability). According to Anderson and Yamamoto (2025), these advancements not only contribute to the reliability of AI systems but also foster a deeper understanding among users, facilitating a more informed and responsible use of AI technologies (https://www.aiuserinsights.org/understanding-ai-decisions). This body of work underscores the dynamic nature of AI research and the collaborative effort required to harness the full potential of LLMs while mitigating associated risks. '''\n",
       "\n",
       "\n",
       "Your output should be just bullet points containing all the citations and their sources. Output: \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "prompt = f\"{context}\\n\\n{instruction}\\n\\n{input_data}\\n\\n{output_indicator}\"\n",
    "Markdown(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Smith et al. (2023) - Journal of AI Research - https://www.journalofairesearch.org/integration-of-llms\n",
       "- Davis and O'Neil (2024) - Ethics in AI Journal - https://www.ethicsinaijournal.org/llm-content-generation-implications\n",
       "- OpenAI team (2025) - AI Transparency Review - https://www.aitransparencyreview.org/enhancing-llm-interpretability\n",
       "- Anderson and Yamamoto (2025) - AI User Insights - https://www.aiuserinsights.org/understanding-ai-decisions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_response(prompt)\n",
    "\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# References:\n",
       "- Smith et al. (2023) - Journal of AI Research - https://www.journalofairesearch.org/integration-of-llms\n",
       "- Davis and O'Neil (2024) - Ethics in AI Journal - https://www.ethicsinaijournal.org/llm-content-generation-implications\n",
       "- OpenAI team (2025) - AI Transparency Review - https://www.aitransparencyreview.org/enhancing-llm-interpretability\n",
       "- Anderson and Yamamoto (2025) - AI User Insights - https://www.aiuserinsights.org/understanding-ai-decisions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_reference_header(output_citation_bullets):\n",
    "    return \"# References\\n\" + output_citation_bullets\n",
    "\n",
    "output_reference_section = add_reference_header(output)\n",
    "\n",
    "Markdown(output_reference_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sub-task 3__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# References:\\n- Smith et al. (2023) - Journal of AI Research - https://www.journalofairesearch.org/integration-of-llms\\n- Davis and O'Neil (2024) - Ethics in AI Journal - https://www.ethicsinaijournal.org/llm-content-generation-implications\\n- OpenAI team (2025) - AI Transparency Review - https://www.aitransparencyreview.org/enhancing-llm-interpretability\\n- Anderson and Yamamoto (2025) - AI User Insights - https://www.aiuserinsights.org/understanding-ai-decisions\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_reference_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\"\n",
    "\n",
    "instruction = \"Convert the following bullet points into markdown format:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# References:\\n- Smith et al. (2023) - Journal of AI Research - https://www.journalofairesearch.org/integration-of-llms\\n- Davis and O'Neil (2024) - Ethics in AI Journal - https://www.ethicsinaijournal.org/llm-content-generation-implications\\n- OpenAI team (2025) - AI Transparency Review - https://www.aitransparencyreview.org/enhancing-llm-interpretability\\n- Anderson and Yamamoto (2025) - AI User Insights - https://www.aiuserinsights.org/understanding-ai-decisions\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = output_reference_section\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"{context}\\n\\n{instruction}\\n\\n{input_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\n",
       "\n",
       "Convert the following bullet points into markdown format:\n",
       "\n",
       "# References:\n",
       "- Smith et al. (2023) - Journal of AI Research - https://www.journalofairesearch.org/integration-of-llms\n",
       "- Davis and O'Neil (2024) - Ethics in AI Journal - https://www.ethicsinaijournal.org/llm-content-generation-implications\n",
       "- OpenAI team (2025) - AI Transparency Review - https://www.aitransparencyreview.org/enhancing-llm-interpretability\n",
       "- Anderson and Yamamoto (2025) - AI User Insights - https://www.aiuserinsights.org/understanding-ai-decisions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# References:\n",
       "- Smith et al. (2023) - Journal of AI Research - [Integration of LLMs](https://www.journalofairesearch.org/integration-of-llms)\n",
       "- Davis and O'Neil (2024) - Ethics in AI Journal - [LLM Content Generation Implications](https://www.ethicsinaijournal.org/llm-content-generation-implications)\n",
       "- OpenAI team (2025) - AI Transparency Review - [Enhancing LLM Interpretability](https://www.aitransparencyreview.org/enhancing-llm-interpretability)\n",
       "- Anderson and Yamamoto (2025) - AI User Insights - [Understanding AI Decisions](https://www.aiuserinsights.org/understanding-ai-decisions)\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_response(prompt)\n",
    "\n",
    "Markdown(output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "- Smith et al. (2023) - Journal of AI Research - [Integration of LLMs](https://www.journalofairesearch.org/integration-of-llms)\n",
    "- Davis and O'Neil (2024) - Ethics in AI Journal - [LLM Content Generation Implications](https://www.ethicsinaijournal.org/llm-content-generation-implications)\n",
    "- OpenAI team (2025) - AI Transparency Review - [Enhancing LLM Interpretability](https://www.aitransparencyreview.org/enhancing-llm-interpretability)\n",
    "- Anderson and Yamamoto (2025) - AI User Insights - [Understanding AI Decisions](https://www.aiuserinsights.org/understanding-ai-decisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the output here looks off because now we have 3 parts to the references instead of just the sentence description and the url source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\"\n",
    "\n",
    "instruction = \"Convert the following bullet points into markdown format:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# References:\\n- Smith et al. (2023) - Journal of AI Research - https://www.journalofairesearch.org/integration-of-llms\\n- Davis and O'Neil (2024) - Ethics in AI Journal - https://www.ethicsinaijournal.org/llm-content-generation-implications\\n- OpenAI team (2025) - AI Transparency Review - https://www.aitransparencyreview.org/enhancing-llm-interpretability\\n- Anderson and Yamamoto (2025) - AI User Insights - https://www.aiuserinsights.org/understanding-ai-decisions\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_indicator = \"Your output should be the bullet point list with the source references as the hyperlinks and the descriptions as the anchor text like this: '''[<anchor text>](<url source>)'''. Output:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\n",
       "\n",
       "Convert the following bullet points into markdown format:\n",
       "\n",
       "# References:\n",
       "- Smith et al. (2023) - Journal of AI Research - https://www.journalofairesearch.org/integration-of-llms\n",
       "- Davis and O'Neil (2024) - Ethics in AI Journal - https://www.ethicsinaijournal.org/llm-content-generation-implications\n",
       "- OpenAI team (2025) - AI Transparency Review - https://www.aitransparencyreview.org/enhancing-llm-interpretability\n",
       "- Anderson and Yamamoto (2025) - AI User Insights - https://www.aiuserinsights.org/understanding-ai-decisions\n",
       "\n",
       "Your output should be the bullet point list with the source references as the hyperlinks and the descriptions as the anchor text like this: '''[<anchor text>](<url source>)'''. Output:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"{context}\\n\\n{instruction}\\n\\n{input_data}\\n\\n{output_indicator}\"\n",
    "\n",
    "Markdown(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## References:\n",
       "- [Smith et al. (2023)](https://www.journalofairesearch.org/integration-of-llms) - Journal of AI Research \n",
       "- [Davis and O'Neil (2024)](https://www.ethicsinaijournal.org/llm-content-generation-implications) - Ethics in AI Journal \n",
       "- [OpenAI team (2025)](https://www.aitransparencyreview.org/enhancing-llm-interpretability) - AI Transparency Review \n",
       "- [Anderson and Yamamoto (2025)](https://www.aiuserinsights.org/understanding-ai-decisions) - AI User Insights "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_response(prompt)\n",
    "\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## References:\\n- [Smith et al. (2023)](https://www.journalofairesearch.org/integration-of-llms) - Journal of AI Research \\n- [Davis and O'Neil (2024)](https://www.ethicsinaijournal.org/llm-content-generation-implications) - Ethics in AI Journal \\n- [OpenAI team (2025)](https://www.aitransparencyreview.org/enhancing-llm-interpretability) - AI Transparency Review \\n- [Anderson and Yamamoto (2025)](https://www.aiuserinsights.org/understanding-ai-decisions) - AI User Insights \""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_indicator = \"Your output should be the bullet point list with the source references as the hyperlinks and the descriptions as the anchor text like this:\\n\\n'''- [<all the anchor text>](<url source>)\\n\\n- [<all the anchor text>](<url source>) ...'''. Output:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\\n\\nConvert the following bullet points into markdown format:\\n\\n# References:\\n- Smith et al. (2023) - Journal of AI Research - https://www.journalofairesearch.org/integration-of-llms\\n- Davis and O'Neil (2024) - Ethics in AI Journal - https://www.ethicsinaijournal.org/llm-content-generation-implications\\n- OpenAI team (2025) - AI Transparency Review - https://www.aitransparencyreview.org/enhancing-llm-interpretability\\n- Anderson and Yamamoto (2025) - AI User Insights - https://www.aiuserinsights.org/understanding-ai-decisions\\n\\nYour output should be the bullet point list with the source references as the hyperlinks and the descriptions as the anchor text like this:\\n\\n'''- [<all the anchor text>](<url source>)\\n\\n- [<all the anchor text>](<url source>) ...'''. Output:\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"{context}\\n\\n{instruction}\\n\\n{input_data}\\n\\n{output_indicator}\"\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- [Smith et al. (2023)](https://www.journalofairesearch.org/integration-of-llms)\n",
       "- [Davis and O'Neil (2024)](https://www.ethicsinaijournal.org/llm-content-generation-implications)\n",
       "- [OpenAI team (2025)](https://www.aitransparencyreview.org/enhancing-llm-interpretability)\n",
       "- [Anderson and Yamamoto (2025)](https://www.aiuserinsights.org/understanding-ai-decisions)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_response(prompt)\n",
    "\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"- [Smith et al. (2023)](https://www.journalofairesearch.org/integration-of-llms)\\n- [Davis and O'Neil (2024)](https://www.ethicsinaijournal.org/llm-content-generation-implications)\\n- [OpenAI team (2025)](https://www.aitransparencyreview.org/enhancing-llm-interpretability)\\n- [Anderson and Yamamoto (2025)](https://www.aiuserinsights.org/understanding-ai-decisions)\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final sub-task we won't use chatgpt because we can simply just add it through a simple function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# References:\n",
       "- [Smith et al. (2023)](https://www.journalofairesearch.org/integration-of-llms)\n",
       "- [Davis and O'Neil (2024)](https://www.ethicsinaijournal.org/llm-content-generation-implications)\n",
       "- [OpenAI team (2025)](https://www.aitransparencyreview.org/enhancing-llm-interpretability)\n",
       "- [Anderson and Yamamoto (2025)](https://www.aiuserinsights.org/understanding-ai-decisions)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_reference_header(output_citation_bullets):\n",
    "    return \"# References:\\n\" + output_citation_bullets\n",
    "\n",
    "output_reference_section = add_reference_header(output)\n",
    "Markdown(output_reference_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's put everything together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "context1_2 = \"You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\"\n",
    "\n",
    "instruction1_2 = \"\"\"Extract all the citations in the following draft essay with their respective source and output a bullet list with all the citations and their sources\"\"\"\n",
    "\n",
    "output_indicator1_2 = \"Your output should be just bullet points containing all the citations and their sources. Output:\"\n",
    "\n",
    "# I generated this mock draft with GPT-4 using the web interface\n",
    "input_data1_2 = \"\"\"The rapid progression of artificial intelligence (AI) has brought significant transformations to numerous sectors, with healthcare being a prominent field experiencing revolutionary changes. In a recent publication by Johnson et al. (2024) in the *Journal of Medical AI Research*, the integration of AI in diagnostic processes has notably increased the accuracy and speed of medical diagnostics (https://www.medicalairesearch.org/ai-in-diagnostics). This evolution in medical technology emphasizes the potential of AI to enhance patient outcomes and streamline healthcare services.\n",
    "\n",
    "Moreover, the use of AI in personalized medicine is becoming increasingly significant, as highlighted by Thompson and colleagues (2023) in their study published in the *Journal of Personalized Medicine*. They discuss how machine learning models are used to tailor treatments based on individual genetic profiles, significantly improving treatment efficacy (https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai). The implications of such advancements underscore the need for robust data protection regulations and ethical guidelines to manage patient data sensitively and securely (https://www.healthprivacy.org/ai-ethics).\n",
    "\n",
    "The challenge of ensuring fairness and eliminating bias in AI algorithms is also critical, especially in high-stakes fields like healthcare. Research by Gupta and Singh (2025) presented in the *AI Ethics Journal* examines the latent biases in AI systems that can lead to disparities in patient care, stressing the importance of developing unbiased AI tools (https://www.aiethicsjournal.org/unbiased-ai-healthcare).\n",
    "\n",
    "In efforts to make AI tools in healthcare more transparent and accountable, the recent initiative by the AI Health Transparency Board (2026) aims to establish standards for AI applications in medicine (https://www.aihealthtransparency.org/standards). These standards are designed to ensure that AI health tools are reliable and their functions are clear to both healthcare providers and patients, fostering trust and understanding in AI-driven processes (https://www.aihealthtrust.org/ai-clarity).\n",
    "\n",
    "Furthermore, the collaboration between AI developers and healthcare professionals is crucial for optimizing the benefits of AI in healthcare, as discussed by Martinez and Liu (2027) in *AI and Healthcare Collaboration Review*. Their research indicates that cooperative development leads to more effective and user-friendly AI solutions that are better aligned with clinical needs (https://www.aihealthcollaboration.org/effective-partnerships).\n",
    "\n",
    "This collective body of research and initiatives highlights the dynamic and evolving nature of AI in healthcare, emphasizing the crucial balance between innovation, ethics, and user-centric development to fully realize the potential of AI in improving health outcomes and patient care.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1_2 = f\"{context1_2}\\n\\n{instruction1_2}\\n\\n{input_data1_2}\\n\\n{output_indicator1_2}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Johnson et al. (2024) - *Journal of Medical AI Research* - https://www.medicalairesearch.org/ai-in-diagnostics\n",
       "- Thompson and colleagues (2023) - *Journal of Personalized Medicine* - https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai\n",
       "- Gupta and Singh (2025) - *AI Ethics Journal* - https://www.aiethicsjournal.org/unbiased-ai-healthcare\n",
       "- AI Health Transparency Board (2026) - https://www.aihealthtransparency.org/standards\n",
       "- Martinez and Liu (2027) - *AI and Healthcare Collaboration Review* - https://www.aihealthcollaboration.org/effective-partnerships"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1_2 = get_response(prompt1_2)\n",
    "Markdown(output1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Johnson et al. (2024) - *Journal of Medical AI Research* - https://www.medicalairesearch.org/ai-in-diagnostics\\n- Thompson and colleagues (2023) - *Journal of Personalized Medicine* - https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai\\n- Gupta and Singh (2025) - *AI Ethics Journal* - https://www.aiethicsjournal.org/unbiased-ai-healthcare\\n- AI Health Transparency Board (2026) - https://www.aihealthtransparency.org/standards\\n- Martinez and Liu (2027) - *AI and Healthcare Collaboration Review* - https://www.aihealthcollaboration.org/effective-partnerships'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem here:\n",
    "\n",
    "ChatGPT did not identify all the urls! Easy to automate the process of checking for this particular case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "context1_2 = \"You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\"\n",
    "\n",
    "instruction1_2 = \"\"\"Extract all the citations in the following draft essay with their respective source.\"\"\"\n",
    "\n",
    "output_indicator1_2 = \"Your output should be the bullet points containing all the citations and their sources. Output:\"\n",
    "\n",
    "# I generated this mock draft with GPT-4 using the web interface\n",
    "input_data1_2 = \"\"\"'''The rapid progression of artificial intelligence (AI) has brought significant transformations to numerous sectors, with healthcare being a prominent field experiencing revolutionary changes. In a recent publication by Johnson et al. (2024) in the *Journal of Medical AI Research*, the integration of AI in diagnostic processes has notably increased the accuracy and speed of medical diagnostics (https://www.medicalairesearch.org/ai-in-diagnostics). This evolution in medical technology emphasizes the potential of AI to enhance patient outcomes and streamline healthcare services.\n",
    "\n",
    "Moreover, the use of AI in personalized medicine is becoming increasingly significant, as highlighted by Thompson and colleagues (2023) in their study published in the *Journal of Personalized Medicine*. They discuss how machine learning models are used to tailor treatments based on individual genetic profiles, significantly improving treatment efficacy (https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai). The implications of such advancements underscore the need for robust data protection regulations and ethical guidelines to manage patient data sensitively and securely (https://www.healthprivacy.org/ai-ethics).\n",
    "\n",
    "The challenge of ensuring fairness and eliminating bias in AI algorithms is also critical, especially in high-stakes fields like healthcare. Research by Gupta and Singh (2025) presented in the *AI Ethics Journal* examines the latent biases in AI systems that can lead to disparities in patient care, stressing the importance of developing unbiased AI tools (https://www.aiethicsjournal.org/unbiased-ai-healthcare).\n",
    "\n",
    "In efforts to make AI tools in healthcare more transparent and accountable, the recent initiative by the AI Health Transparency Board (2026) aims to establish standards for AI applications in medicine (https://www.aihealthtransparency.org/standards). These standards are designed to ensure that AI health tools are reliable and their functions are clear to both healthcare providers and patients, fostering trust and understanding in AI-driven processes (https://www.aihealthtrust.org/ai-clarity).\n",
    "\n",
    "Furthermore, the collaboration between AI developers and healthcare professionals is crucial for optimizing the benefits of AI in healthcare, as discussed by Martinez and Liu (2027) in *AI and Healthcare Collaboration Review*. Their research indicates that cooperative development leads to more effective and user-friendly AI solutions that are better aligned with clinical needs (https://www.aihealthcollaboration.org/effective-partnerships).\n",
    "\n",
    "This collective body of research and initiatives highlights the dynamic and evolving nature of AI in healthcare, emphasizing the crucial balance between innovation, ethics, and user-centric development to fully realize the potential of AI in improving health outcomes and patient care.'''\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\n",
       "\n",
       "Extract all the citations in the following draft essay with their respective source.\n",
       "\n",
       "'''The rapid progression of artificial intelligence (AI) has brought significant transformations to numerous sectors, with healthcare being a prominent field experiencing revolutionary changes. In a recent publication by Johnson et al. (2024) in the *Journal of Medical AI Research*, the integration of AI in diagnostic processes has notably increased the accuracy and speed of medical diagnostics (https://www.medicalairesearch.org/ai-in-diagnostics). This evolution in medical technology emphasizes the potential of AI to enhance patient outcomes and streamline healthcare services.\n",
       "\n",
       "Moreover, the use of AI in personalized medicine is becoming increasingly significant, as highlighted by Thompson and colleagues (2023) in their study published in the *Journal of Personalized Medicine*. They discuss how machine learning models are used to tailor treatments based on individual genetic profiles, significantly improving treatment efficacy (https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai). The implications of such advancements underscore the need for robust data protection regulations and ethical guidelines to manage patient data sensitively and securely (https://www.healthprivacy.org/ai-ethics).\n",
       "\n",
       "The challenge of ensuring fairness and eliminating bias in AI algorithms is also critical, especially in high-stakes fields like healthcare. Research by Gupta and Singh (2025) presented in the *AI Ethics Journal* examines the latent biases in AI systems that can lead to disparities in patient care, stressing the importance of developing unbiased AI tools (https://www.aiethicsjournal.org/unbiased-ai-healthcare).\n",
       "\n",
       "In efforts to make AI tools in healthcare more transparent and accountable, the recent initiative by the AI Health Transparency Board (2026) aims to establish standards for AI applications in medicine (https://www.aihealthtransparency.org/standards). These standards are designed to ensure that AI health tools are reliable and their functions are clear to both healthcare providers and patients, fostering trust and understanding in AI-driven processes (https://www.aihealthtrust.org/ai-clarity).\n",
       "\n",
       "Furthermore, the collaboration between AI developers and healthcare professionals is crucial for optimizing the benefits of AI in healthcare, as discussed by Martinez and Liu (2027) in *AI and Healthcare Collaboration Review*. Their research indicates that cooperative development leads to more effective and user-friendly AI solutions that are better aligned with clinical needs (https://www.aihealthcollaboration.org/effective-partnerships).\n",
       "\n",
       "This collective body of research and initiatives highlights the dynamic and evolving nature of AI in healthcare, emphasizing the crucial balance between innovation, ethics, and user-centric development to fully realize the potential of AI in improving health outcomes and patient care.'''\n",
       "\n",
       "Your output should be the bullet points containing all the citations and their sources. Output:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt1_2 = f\"{context1_2}\\n\\n{instruction1_2}\\n\\n{input_data1_2}\\n\\n{output_indicator1_2}\"\n",
    "\n",
    "Markdown(prompt1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Johnson et al. (2024) in the *Journal of Medical AI Research*: https://www.medicalairesearch.org/ai-in-diagnostics\n",
       "- Thompson and colleagues (2023) in the *Journal of Personalized Medicine*: https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai\n",
       "- Gupta and Singh (2025) in the *AI Ethics Journal*: https://www.aiethicsjournal.org/unbiased-ai-healthcare\n",
       "- AI Health Transparency Board (2026): https://www.aihealthtransparency.org/standards\n",
       "- Martinez and Liu (2027) in *AI and Healthcare Collaboration Review*: https://www.aihealthcollaboration.org/effective-partnerships"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1_2 = get_response(prompt1_2)\n",
    "Markdown(output1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Johnson et al. (2024) in the *Journal of Medical AI Research*: https://www.medicalairesearch.org/ai-in-diagnostics\\n- Thompson and colleagues (2023) in the *Journal of Personalized Medicine*: https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai\\n- Gupta and Singh (2025) in the *AI Ethics Journal*: https://www.aiethicsjournal.org/unbiased-ai-healthcare\\n- AI Health Transparency Board (2026): https://www.aihealthtransparency.org/standards\\n- Martinez and Liu (2027) in *AI and Healthcare Collaboration Review*: https://www.aihealthcollaboration.org/effective-partnerships'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt_question, system_message=\"You are a helpful research and programming assistant\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_message},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\n",
       "\n",
       "Extract all the citations in the following draft essay with their respective source.\n",
       "\n",
       "'''The rapid progression of artificial intelligence (AI) has brought significant transformations to numerous sectors, with healthcare being a prominent field experiencing revolutionary changes. In a recent publication by Johnson et al. (2024) in the *Journal of Medical AI Research*, the integration of AI in diagnostic processes has notably increased the accuracy and speed of medical diagnostics (https://www.medicalairesearch.org/ai-in-diagnostics). This evolution in medical technology emphasizes the potential of AI to enhance patient outcomes and streamline healthcare services.\n",
       "\n",
       "Moreover, the use of AI in personalized medicine is becoming increasingly significant, as highlighted by Thompson and colleagues (2023) in their study published in the *Journal of Personalized Medicine*. They discuss how machine learning models are used to tailor treatments based on individual genetic profiles, significantly improving treatment efficacy (https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai). The implications of such advancements underscore the need for robust data protection regulations and ethical guidelines to manage patient data sensitively and securely (https://www.healthprivacy.org/ai-ethics).\n",
       "\n",
       "The challenge of ensuring fairness and eliminating bias in AI algorithms is also critical, especially in high-stakes fields like healthcare. Research by Gupta and Singh (2025) presented in the *AI Ethics Journal* examines the latent biases in AI systems that can lead to disparities in patient care, stressing the importance of developing unbiased AI tools (https://www.aiethicsjournal.org/unbiased-ai-healthcare).'''\n",
       "\n",
       "Your output should be the bullet points containing all the citations and their sources. Output:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context1_2 = \"You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\"\n",
    "\n",
    "instruction1_2 = \"\"\"Extract all the citations in the following draft essay with their respective source.\"\"\"\n",
    "\n",
    "output_indicator1_2 = \"Your output should be the bullet points containing all the citations and their sources. Output:\"\n",
    "\n",
    "# Here we cut input data in half to see if we detect progress.\n",
    "input_data1_2 = \"\"\"'''The rapid progression of artificial intelligence (AI) has brought significant transformations to numerous sectors, with healthcare being a prominent field experiencing revolutionary changes. In a recent publication by Johnson et al. (2024) in the *Journal of Medical AI Research*, the integration of AI in diagnostic processes has notably increased the accuracy and speed of medical diagnostics (https://www.medicalairesearch.org/ai-in-diagnostics). This evolution in medical technology emphasizes the potential of AI to enhance patient outcomes and streamline healthcare services.\n",
    "\n",
    "Moreover, the use of AI in personalized medicine is becoming increasingly significant, as highlighted by Thompson and colleagues (2023) in their study published in the *Journal of Personalized Medicine*. They discuss how machine learning models are used to tailor treatments based on individual genetic profiles, significantly improving treatment efficacy (https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai). The implications of such advancements underscore the need for robust data protection regulations and ethical guidelines to manage patient data sensitively and securely (https://www.healthprivacy.org/ai-ethics).\n",
    "\n",
    "The challenge of ensuring fairness and eliminating bias in AI algorithms is also critical, especially in high-stakes fields like healthcare. Research by Gupta and Singh (2025) presented in the *AI Ethics Journal* examines the latent biases in AI systems that can lead to disparities in patient care, stressing the importance of developing unbiased AI tools (https://www.aiethicsjournal.org/unbiased-ai-healthcare).'''\"\"\"\n",
    "\n",
    "prompt1_2 = f\"{context1_2}\\n\\n{instruction1_2}\\n\\n{input_data1_2}\\n\\n{output_indicator1_2}\"\n",
    "\n",
    "Markdown(prompt1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Johnson et al. (2024) in the *Journal of Medical AI Research* - https://www.medicalairesearch.org/ai-in-diagnostics\n",
       "- Thompson and colleagues (2023) in the *Journal of Personalized Medicine* - https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai\n",
       "- Gupta and Singh (2025) in the *AI Ethics Journal* - https://www.aiethicsjournal.org/unbiased-ai-healthcare"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1_2 = get_response(prompt1_2)\n",
    "Markdown(output1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Johnson et al. (2024) in the *Journal of Medical AI Research* - https://www.medicalairesearch.org/ai-in-diagnostics\\n- Thompson and colleagues (2023) in the *Journal of Personalized Medicine* - https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai\\n- Gupta and Singh (2025) in the *AI Ethics Journal* - https://www.aiethicsjournal.org/unbiased-ai-healthcare'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\n",
       "\n",
       "Extract all the citations in the following draft essay with their respective source.\n",
       "\n",
       "'''The rapid progression of artificial intelligence (AI) has brought significant transformations to numerous sectors, with healthcare being a prominent field experiencing revolutionary changes. In a recent publication by Johnson et al. (2024) in the *Journal of Medical AI Research*, the integration of AI in diagnostic processes has notably increased the accuracy and speed of medical diagnostics (https://www.medicalairesearch.org/ai-in-diagnostics). This evolution in medical technology emphasizes the potential of AI to enhance patient outcomes and streamline healthcare services.\n",
       "\n",
       "Moreover, the use of AI in personalized medicine is becoming increasingly significant, as highlighted by Thompson and colleagues (2023) in their study published in the *Journal of Personalized Medicine*. They discuss how machine learning models are used to tailor treatments based on individual genetic profiles, significantly improving treatment efficacy (https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai). The implications of such advancements underscore the need for robust data protection regulations and ethical guidelines to manage patient data sensitively and securely (https://www.healthprivacy.org/ai-ethics).\n",
       "\n",
       "The challenge of ensuring fairness and eliminating bias in AI algorithms is also critical, especially in high-stakes fields like healthcare. Research by Gupta and Singh (2025) presented in the *AI Ethics Journal* examines the latent biases in AI systems that can lead to disparities in patient care, stressing the importance of developing unbiased AI tools (https://www.aiethicsjournal.org/unbiased-ai-healthcare).'''\n",
       "\n",
       "Your output should be the bullet points containing all the citations and their urls sources. Make sure to extract all the links in the draft. Output:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context1_2 = \"You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\"\n",
    "\n",
    "instruction1_2 = \"\"\"Extract all the citations in the following draft essay with their respective source.\"\"\"\n",
    "\n",
    "output_indicator1_2 = \"Your output should be the bullet points containing all the citations and their urls sources. Make sure to extract all the links in the draft. Output:\"\n",
    "\n",
    "# Here we cut input data in half to see if we detect progress.\n",
    "input_data1_2 = \"\"\"'''The rapid progression of artificial intelligence (AI) has brought significant transformations to numerous sectors, with healthcare being a prominent field experiencing revolutionary changes. In a recent publication by Johnson et al. (2024) in the *Journal of Medical AI Research*, the integration of AI in diagnostic processes has notably increased the accuracy and speed of medical diagnostics (https://www.medicalairesearch.org/ai-in-diagnostics). This evolution in medical technology emphasizes the potential of AI to enhance patient outcomes and streamline healthcare services.\n",
    "\n",
    "Moreover, the use of AI in personalized medicine is becoming increasingly significant, as highlighted by Thompson and colleagues (2023) in their study published in the *Journal of Personalized Medicine*. They discuss how machine learning models are used to tailor treatments based on individual genetic profiles, significantly improving treatment efficacy (https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai). The implications of such advancements underscore the need for robust data protection regulations and ethical guidelines to manage patient data sensitively and securely (https://www.healthprivacy.org/ai-ethics).\n",
    "\n",
    "The challenge of ensuring fairness and eliminating bias in AI algorithms is also critical, especially in high-stakes fields like healthcare. Research by Gupta and Singh (2025) presented in the *AI Ethics Journal* examines the latent biases in AI systems that can lead to disparities in patient care, stressing the importance of developing unbiased AI tools (https://www.aiethicsjournal.org/unbiased-ai-healthcare).'''\"\"\"\n",
    "\n",
    "prompt1_2 = f\"{context1_2}\\n\\n{instruction1_2}\\n\\n{input_data1_2}\\n\\n{output_indicator1_2}\"\n",
    "\n",
    "Markdown(prompt1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Johnson et al. (2024) in the *Journal of Medical AI Research* (https://www.medicalairesearch.org/ai-in-diagnostics)\n",
       "- Thompson and colleagues (2023) in the *Journal of Personalized Medicine* (https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai)\n",
       "- Gupta and Singh (2025) in the *AI Ethics Journal* (https://www.aiethicsjournal.org/unbiased-ai-healthcare)\n",
       "- https://www.healthprivacy.org/ai-ethics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1_2 = get_response(prompt1_2)\n",
    "\n",
    "Markdown(output1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Johnson et al. (2024) in the *Journal of Medical AI Research* (https://www.medicalairesearch.org/ai-in-diagnostics)\\n- Thompson and colleagues (2023) in the *Journal of Personalized Medicine* (https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai)\\n- Gupta and Singh (2025) in the *AI Ethics Journal* (https://www.aiethicsjournal.org/unbiased-ai-healthcare)\\n- https://www.healthprivacy.org/ai-ethics'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a helpful research assistant specialized in extracting useful information from content and helping with research essays and reports.\n",
       "\n",
       "Convert the following bullet points into markdown format:\n",
       "\n",
       "'''- Johnson et al. (2024) in the *Journal of Medical AI Research* (https://www.medicalairesearch.org/ai-in-diagnostics)\n",
       "- Thompson and colleagues (2023) in the *Journal of Personalized Medicine* (https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai)\n",
       "- Gupta and Singh (2025) in the *AI Ethics Journal* (https://www.aiethicsjournal.org/unbiased-ai-healthcare)\n",
       "- https://www.healthprivacy.org/ai-ethics'''\n",
       "\n",
       "Your output should be the bullet point list with the source references as the hyperlinks and the descriptions as the anchor text like this:\n",
       "\n",
       "'''- [<all the anchor text>](<url source>)\n",
       "\n",
       "- [<all the anchor text>](<url source>) ...'''. Output:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context3 = context1_2\n",
    "\n",
    "instruction3 = \"Convert the following bullet points into markdown format:\"\n",
    "\n",
    "output_indicator3 = \"Your output should be the bullet point list with the source references as the hyperlinks and the descriptions as the anchor text like this:\\n\\n'''- [<all the anchor text>](<url source>)\\n\\n- [<all the anchor text>](<url source>) ...'''. Output:\"\n",
    "\n",
    "input_data3 = \"'''\" + output1_2 + \"'''\"\n",
    "\n",
    "prompt3 = f\"{context3}\\n\\n{instruction3}\\n\\n{input_data3}\\n\\n{output_indicator3}\"\n",
    "\n",
    "Markdown(prompt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- [Johnson et al. (2024) in the *Journal of Medical AI Research](https://www.medicalairesearch.org/ai-in-diagnostics)\n",
       "- [Thompson and colleagues (2023) in the *Journal of Personalized Medicine*](https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai)\n",
       "- [Gupta and Singh (2025) in the *AI Ethics Journal*](https://www.aiethicsjournal.org/unbiased-ai-healthcare)\n",
       "- [Health Privacy](https://www.healthprivacy.org/ai-ethics)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output3 = get_response(prompt3)\n",
    "\n",
    "Markdown(output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- [Johnson et al. (2024) in the *Journal of Medical AI Research](https://www.medicalairesearch.org/ai-in-diagnostics)\\n- [Thompson and colleagues (2023) in the *Journal of Personalized Medicine*](https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai)\\n- [Gupta and Singh (2025) in the *AI Ethics Journal*](https://www.aiethicsjournal.org/unbiased-ai-healthcare)\\n- [Health Privacy](https://www.healthprivacy.org/ai-ethics)'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting everything together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# References:\n",
       "- [Johnson et al. (2024) in the *Journal of Medical AI Research](https://www.medicalairesearch.org/ai-in-diagnostics)\n",
       "- [Thompson and colleagues (2023) in the *Journal of Personalized Medicine*](https://www.journalofpersonalizedmedicine.org/tailoring-treatments-with-ai)\n",
       "- [Gupta and Singh (2025) in the *AI Ethics Journal*](https://www.aiethicsjournal.org/unbiased-ai-healthcare)\n",
       "- [Health Privacy](https://www.healthprivacy.org/ai-ethics)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output4 = add_reference_header(output3)\n",
    "\n",
    "Markdown(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reference_section(input_data):\n",
    "    \"\"\"Extract all the citations in the input data and output a markdown-formatted reference section.\"\"\"\n",
    "    output_refs = get_response(input_data, prompt1_2)\n",
    "    output_refs_markdown = get_response(output_refs, prompt3)\n",
    "    output_refs_markdown_with_header = add_reference_header(output_refs_markdown)\n",
    "    return output_refs_markdown_with_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "The field of artificial intelligence (AI) continues to evolve rapidly, with recent advancements significantly enhancing various capabilities, particularly in natural language processing (NLP). A pivotal study by Brown et al. (2023) published in the AI Advancements Journal highlights the development of advanced algorithms that improve the efficiency and accuracy of language models (https://www.aiadvancementsjournal.org/advanced-algorithms). These improvements have opened new avenues for real-time translation services and more nuanced human-computer interactions, setting a new standard in technological integration.\n",
       "\n",
       "Furthermore, the implications of AI in decision-making processes have prompted a considerable amount of ethical scrutiny. A report by Thompson and Lee (2024) in the AI Ethics Quarterly discusses how AI systems are increasingly used in judicial and healthcare settings, raising concerns about fairness and transparency (https://www.aiethicsquarterly.org/ai-judicial-use). The potential for AI to impact significant societal decisions necessitates ongoing research to ensure ethical deployment, as explored by Morales and Kumar (2024) who emphasize the need for robust frameworks to manage AI's societal impacts (https://www.aisocietalimpact.org/frameworks).\n",
       "\n",
       "In response to these challenges, initiatives aiming to enhance the accountability of AI systems have gained momentum. Notably, an initiative detailed by Zhao and Michelson (2025) in the AI Accountability Forum describes efforts to implement standards that ensure AI systems are auditable and explainable, enhancing public trust in AI technologies (https://www.aiaccountabilityforum.org/standards). This initiative is part of a broader movement to secure a responsible future for AI, as discussed by Patel and Singh (2025), who highlight collaborative efforts to harmonize international AI regulations (https://www.globalairegulations.org/harmonization). This collective endeavor is critical to harnessing AI's full potential while safeguarding against its risks.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_test = \"\"\"\n",
    "The field of artificial intelligence (AI) continues to evolve rapidly, with recent advancements significantly enhancing various capabilities, particularly in natural language processing (NLP). A pivotal study by Brown et al. (2023) published in the AI Advancements Journal highlights the development of advanced algorithms that improve the efficiency and accuracy of language models (https://www.aiadvancementsjournal.org/advanced-algorithms). These improvements have opened new avenues for real-time translation services and more nuanced human-computer interactions, setting a new standard in technological integration.\n",
    "\n",
    "Furthermore, the implications of AI in decision-making processes have prompted a considerable amount of ethical scrutiny. A report by Thompson and Lee (2024) in the AI Ethics Quarterly discusses how AI systems are increasingly used in judicial and healthcare settings, raising concerns about fairness and transparency (https://www.aiethicsquarterly.org/ai-judicial-use). The potential for AI to impact significant societal decisions necessitates ongoing research to ensure ethical deployment, as explored by Morales and Kumar (2024) who emphasize the need for robust frameworks to manage AI's societal impacts (https://www.aisocietalimpact.org/frameworks).\n",
    "\n",
    "In response to these challenges, initiatives aiming to enhance the accountability of AI systems have gained momentum. Notably, an initiative detailed by Zhao and Michelson (2025) in the AI Accountability Forum describes efforts to implement standards that ensure AI systems are auditable and explainable, enhancing public trust in AI technologies (https://www.aiaccountabilityforum.org/standards). This initiative is part of a broader movement to secure a responsible future for AI, as discussed by Patel and Singh (2025), who highlight collaborative efforts to harmonize international AI regulations (https://www.globalairegulations.org/harmonization). This collective endeavor is critical to harnessing AI's full potential while safeguarding against its risks.\n",
    "\"\"\"\n",
    "\n",
    "Markdown(input_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# References:\n",
       "- [Brown et al. (2023), *AI Advancements Journal*](https://www.aiadvancementsjournal.org/advanced-algorithms)\n",
       "\n",
       "- [Thompson and Lee (2024), *AI Ethics Quarterly*](https://www.aiethicsquarterly.org/ai-judicial-use)\n",
       "\n",
       "- [Morales and Kumar (2024)](https://www.aisocietalimpact.org/frameworks)\n",
       "\n",
       "- [Zhao and Michelson (2025), *AI Accountability Forum*](https://www.aiaccountabilityforum.org/standards)\n",
       "\n",
       "- [Patel and Singh (2025)](https://www.globalairegulations.org/harmonization)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_refs_section = create_reference_section(input_data_test)\n",
    "\n",
    "Markdown(output_refs_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-prompt-eng",
   "language": "python",
   "name": "oreilly-prompt-eng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

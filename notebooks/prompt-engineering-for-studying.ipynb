{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg_question_extractor = \"\"\"\n",
    "IDENTITY\n",
    "You are an advanced AI with a 419 IQ that excels at asking brilliant questions of people. You specialize in extracting the questions out of a piece of content, word for word, and then figuring out what made the questions so good.\n",
    "\n",
    "GOAL\n",
    "Extract all the questions from the content.\n",
    "\n",
    "Determine what made the questions so good at getting surprising and high-quality answers from the person being asked.\n",
    "\n",
    "OUTPUT\n",
    "In a section called QUESTIONS, list all questions as a series of bullet points.\n",
    "\n",
    "In a section called ANALYSIS, give a set 15-word bullet points that capture the genius of the questions that were asked.\n",
    "\n",
    "In a section called RECOMMENDATIONS FOR INTERVIEWERS, give a set of 15-word bullet points that give prescriptive advice to interviewers on how to ask questions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Make a list with all the possible questions that are answerable by just reading the following text:\"\n",
    "\n",
    "input_data = \"\"\"\n",
    "Large language models (LLMs) can perform complex reasoning by generating intermediate reasoning steps. Providing these steps for prompting demonstrations is called chain-of-thought (CoT) prompting. CoT prompting has two major paradigms. One leverages a simple prompt like \"Let's think step by step\" to facilitate step-by-step thinking before answering a question. The other uses a few manual demonstrations one by one, each composed of a question and a reasoning chain that leads to an answer. The superior performance of the second paradigm hinges on the hand-crafting of task-specific demonstrations one by one. We show that such manual efforts may be eliminated by leveraging LLMs with the \"Let's think step by step\" prompt to generate reasoning chains for demonstrations one by one, i.e., let's think not just step by step, but also one by one. However, these generated chains often come with mistakes. To mitigate the effect of such mistakes, we find that diversity matters for automatically constructing demonstrations. We propose an automatic CoT prompting method: Auto-CoT. It samples questions with diversity and generates reasoning chains to construct demonstrations. On ten public benchmark reasoning tasks with GPT-3, Auto-CoT consistently matches or exceeds the performance of the CoT paradigm that requires manual designs of demonstrations.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-prompt-eng",
   "language": "python",
   "name": "oreilly-prompt-eng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
